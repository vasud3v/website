name: 24/7 Continuous Video Scraper & Uploader

on:
  schedule:
    - cron: '0 */5 * * *'
  
  workflow_dispatch:
    inputs:
      max_videos:
        description: 'Max videos to process (0 = unlimited)'
        required: false
        default: '0'
        type: string
      workers:
        description: 'Number of parallel workers'
        required: false
        default: '32'
        type: string
  
  push:
    branches:
      - main
    paths:
      - '.github/workflows/continuous-scraper.yml'

env:
  PYTHON_VERSION: '3.10'
  MAX_RUNTIME_MINUTES: 290

jobs:
  scrape-download-enrich-upload:
    runs-on: ubuntu-latest
    timeout-minutes: 300
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg wget curl
          
          # Install Chrome instead of Chromium (more reliable)
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
          # Install ChromeDriver
          CHROME_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d '.' -f 1)
          wget -q "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}" -O /tmp/chromedriver_version
          CHROMEDRIVER_VERSION=$(cat /tmp/chromedriver_version)
          wget -q "https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip" -O /tmp/chromedriver.zip
          sudo unzip -q /tmp/chromedriver.zip -d /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
          
          echo "✅ Chrome and ChromeDriver installed"
          google-chrome --version
          chromedriver --version
      
      - name: Install Python Dependencies
        timeout-minutes: 10
        run: |
          python -m pip install --upgrade pip
          pip install -r javmix/requirements.txt
          pip install -r javdatabase/requirements.txt
          pip install -r upload_pipeline/requirements.txt
          pip install seleniumbase undetected-chromedriver deep-translator internetarchive
          echo "✅ Python dependencies installed"
      
      - name: Configure Environment
        timeout-minutes: 5
        run: |
          echo "SEEKSTREAMING_API_KEY=${{ secrets.SEEKSTREAMING_API_KEY }}" >> upload_pipeline/.env
          echo "STREAMTAPE_USERNAME=${{ secrets.STREAMTAPE_USERNAME }}" >> upload_pipeline/.env
          echo "STREAMTAPE_PASSWORD=${{ secrets.STREAMTAPE_PASSWORD }}" >> upload_pipeline/.env
          echo "TURBOVIPLAY_EMAIL=${{ secrets.TURBOVIPLAY_EMAIL }}" >> upload_pipeline/.env
          echo "TURBOVIPLAY_USERNAME=${{ secrets.TURBOVIPLAY_USERNAME }}" >> upload_pipeline/.env
          echo "TURBOVIPLAY_PASSWORD=${{ secrets.TURBOVIPLAY_PASSWORD }}" >> upload_pipeline/.env
          echo "TURBOVIPLAY_API_KEY=${{ secrets.TURBOVIPLAY_API_KEY }}" >> upload_pipeline/.env
          echo "VIDOZA_EMAIL=${{ secrets.VIDOZA_EMAIL }}" >> upload_pipeline/.env
          echo "VIDOZA_PASSWORD=${{ secrets.VIDOZA_PASSWORD }}" >> upload_pipeline/.env
          echo "VIDOZA_API_KEY=${{ secrets.VIDOZA_API_KEY }}" >> upload_pipeline/.env
          echo "UPLOADY_EMAIL=${{ secrets.UPLOADY_EMAIL }}" >> upload_pipeline/.env
          echo "UPLOADY_USERNAME=${{ secrets.UPLOADY_USERNAME }}" >> upload_pipeline/.env
          echo "UPLOADY_API_KEY=${{ secrets.UPLOADY_API_KEY }}" >> upload_pipeline/.env
          echo "UPLOAD18_API_KEY=${{ secrets.UPLOAD18_API_KEY }}" >> upload_pipeline/.env
          echo "IA_ACCESS_KEY=${{ secrets.IA_ACCESS_KEY }}" >> upload_pipeline/.env
          echo "IA_SECRET_KEY=${{ secrets.IA_SECRET_KEY }}" >> upload_pipeline/.env
          export IA_ACCESS_KEY="${{ secrets.IA_ACCESS_KEY }}"
          export IA_SECRET_KEY="${{ secrets.IA_SECRET_KEY }}"
          mkdir -p database downloaded_files upload_pipeline/upload_results javmix/downloaded_files javdatabase/downloaded_files
      
      - name: Restore Previous State
        uses: actions/cache/restore@v3
        with:
          path: |
            database/
            sitemap_videos.json
            javmix/new_videos.json
          key: scraper-state-${{ github.run_number }}
          restore-keys: |
            scraper-state-
      
      - name: Check for New Videos
        id: check_new
        run: |
          echo "Checking for new videos..."
          python javmix/monitor_new_videos.py --rss-only || true
          if [ -f "javmix/new_videos.json" ]; then
            echo "new_videos=1" >> $GITHUB_OUTPUT
            echo "Found new videos"
          else
            echo "new_videos=0" >> $GITHUB_OUTPUT
            echo "No new videos found"
          fi
      
      - name: Scrape New Videos
        if: steps.check_new.outputs.new_videos > 0
        run: |
          echo "Scraping ${{ steps.check_new.outputs.new_videos }} new videos..."
          python javmix/auto_scrape_new.py --scrape-pending
      
      - name: Run Continuous Workflow
        id: workflow
        run: |
          echo "Starting continuous workflow..."
          python .github/workflows/continuous_workflow.py --max-runtime ${{ env.MAX_RUNTIME_MINUTES }} --workers ${{ github.event.inputs.workers || '32' }} --max-videos ${{ github.event.inputs.max_videos || '0' }}
      
      - name: Save State
        if: always()
        uses: actions/cache/save@v3
        with:
          path: |
            database/
            sitemap_videos.json
            javmix/new_videos.json
          key: scraper-state-${{ github.run_number }}
      
      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: workflow-results-${{ github.run_number }}
          path: |
            database/
            upload_pipeline/upload_results/
            *.log
          retention-days: 7
      
      - name: Generate Summary
        if: always()
        run: |
          echo "## Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f "workflow_stats.json" ]; then
            echo "### Statistics" >> $GITHUB_STEP_SUMMARY
            echo "Check workflow_stats.json for details" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Run" >> $GITHUB_STEP_SUMMARY
          echo "Scheduled in 5 hours" >> $GITHUB_STEP_SUMMARY
